{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9886675,"sourceType":"datasetVersion","datasetId":6071407},{"sourceId":9886689,"sourceType":"datasetVersion","datasetId":6071419}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom transformers import BertModel, BertTokenizer\n\n# Load data\ntrain_data = pd.read_csv('/kaggle/input/ml-project-dataset/train/subtask_a_train.csv')\ntarget_data = pd.read_csv('/kaggle/input/target-data-files/target_t.csv')\n\n# Image transformations\nimage_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Dataset class\nclass IdiomImageDataset(Dataset):\n    def __init__(self, dataframe, target_df, image_dir):\n        self.dataframe = dataframe\n        self.target_df = target_df\n        self.image_dir = image_dir\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        row = self.dataframe.iloc[index]\n        target_row = self.target_df.iloc[index]\n        sentence = row['sentence']\n        idiom_name = row['compound'].replace(\"'\", \"_\")\n        image_names = [row[f'image{i}_name'] for i in range(1, 6)]\n\n        expected_order = eval(target_row['target'])\n        expected_order = [x - 1 for x in expected_order]\n\n        inputs = self.tokenizer(sentence, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n        images = []\n        for img_name in image_names:\n            img_path = os.path.join(self.image_dir, idiom_name, img_name)\n            img = Image.open(img_path).convert('RGB')\n            img = image_transforms(img)\n            images.append(img)\n        images_tensor = torch.stack(images)\n        expected_order_tensor = torch.tensor(expected_order, dtype=torch.long)\n        return inputs['input_ids'].squeeze(0), inputs['attention_mask'].squeeze(0), images_tensor, expected_order_tensor\n\n# Model class with dropout layers and cross-entropy for ranking\nclass MultimodalRankingModel(nn.Module):\n    def __init__(self):\n        super(MultimodalRankingModel, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.resnet = models.resnet50(weights='DEFAULT')\n        self.resnet.fc = nn.Identity()\n        self.fc1 = nn.Linear(768 + 2048, 512)\n        self.dropout = nn.Dropout(0.3)\n        self.fc2 = nn.Linear(512, 5)\n\n    def forward(self, input_ids, attention_mask, images):\n        text_features = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n        text_features = text_features.mean(dim=1)\n        \n        batch_size, num_images, channels, height, width = images.size()\n        images = images.view(batch_size * num_images, channels, height, width)\n        image_features = self.resnet(images)\n        image_features = image_features.view(batch_size, num_images, -1)\n        \n        combined_features = torch.cat((text_features.unsqueeze(1).expand(-1, num_images, -1), image_features), dim=2)\n        x = torch.relu(self.fc1(combined_features))\n        x = self.dropout(x)\n        rankings = self.fc2(x).squeeze(-1)  # Shape: [batch_size, num_images]\n        \n        return rankings\n\n# Data preparation\nimage_folder = '/kaggle/input/ml-project-dataset/train'\ndataset = IdiomImageDataset(train_data, target_data, image_folder)\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# Training setup\nmodel = MultimodalRankingModel()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\ncriterion = nn.CrossEntropyLoss()\n\n# Training function\ndef train_model(model, data_loader, criterion, optimizer, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for input_ids, attention_mask, images, expected_order in data_loader:\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask, images)\n            loss = 0\n            for i in range(outputs.size(1)):  # Loop over each image's rank\n                loss += criterion(outputs[:, i], expected_order[:, i])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        \n        print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data_loader)}')\n\n# Run training\ntrain_model(model, train_loader, criterion, optimizer, epochs=10)\ntorch.save(model.state_dict(), 'multimodal_ranking_model.pth')\n\n# Evaluation function\ndef evaluate_model(model, data_loader):\n    model.eval()\n    all_predictions = []\n    with torch.no_grad():\n        for input_ids, attention_mask, images, _ in data_loader:\n            outputs = model(input_ids, attention_mask, images)\n            rankings = torch.argsort(outputs, dim=1)\n            all_predictions.extend(rankings.cpu().numpy())\n    return all_predictions\n\n# Calculate ranking accuracy\npredicted_rankings = evaluate_model(model, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T17:26:41.640039Z","iopub.execute_input":"2024-11-12T17:26:41.640519Z","iopub.status.idle":"2024-11-12T17:51:51.631021Z","shell.execute_reply.started":"2024-11-12T17:26:41.640472Z","shell.execute_reply":"2024-11-12T17:51:51.629182Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 8.043292045593262\nEpoch 2/10, Loss: 7.724140167236328\nEpoch 3/10, Loss: 7.4763606786727905\nEpoch 4/10, Loss: 7.143829822540283\nEpoch 5/10, Loss: 6.789019227027893\nEpoch 6/10, Loss: 6.301056861877441\nEpoch 7/10, Loss: 5.747622489929199\nEpoch 8/10, Loss: 5.074761748313904\nEpoch 9/10, Loss: 4.441108584403992\nEpoch 10/10, Loss: 3.8312588334083557\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"predicted_rankings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T17:52:04.188276Z","iopub.execute_input":"2024-11-12T17:52:04.189534Z","iopub.status.idle":"2024-11-12T17:52:04.208142Z","shell.execute_reply.started":"2024-11-12T17:52:04.189462Z","shell.execute_reply":"2024-11-12T17:52:04.206900Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[array([[1, 4, 0, 0, 0],\n        [2, 2, 4, 3, 3],\n        [4, 1, 3, 1, 2],\n        [3, 3, 2, 2, 4],\n        [0, 0, 1, 4, 1]]),\n array([[1, 4, 2, 3, 3],\n        [4, 2, 0, 0, 0],\n        [2, 0, 3, 1, 4],\n        [0, 1, 4, 2, 1],\n        [3, 3, 1, 4, 2]]),\n array([[0, 0, 3, 1, 2],\n        [2, 4, 4, 3, 1],\n        [1, 2, 0, 4, 3],\n        [4, 3, 2, 2, 4],\n        [3, 1, 1, 0, 0]]),\n array([[3, 0, 4, 4, 4],\n        [2, 1, 1, 2, 2],\n        [1, 3, 0, 1, 3],\n        [0, 2, 3, 0, 0],\n        [4, 4, 2, 3, 1]]),\n array([[2, 2, 1, 4, 4],\n        [3, 1, 3, 1, 0],\n        [0, 3, 0, 0, 3],\n        [1, 0, 2, 3, 1],\n        [4, 4, 4, 2, 2]]),\n array([[4, 4, 3, 1, 3],\n        [0, 0, 4, 3, 1],\n        [2, 2, 1, 0, 2],\n        [1, 1, 0, 2, 0],\n        [3, 3, 2, 4, 4]]),\n array([[2, 3, 0, 0, 0],\n        [3, 1, 1, 1, 2],\n        [0, 2, 4, 4, 4],\n        [4, 4, 3, 2, 3],\n        [1, 0, 2, 3, 1]]),\n array([[2, 4, 1, 1, 0],\n        [3, 3, 2, 0, 1],\n        [0, 2, 0, 3, 2],\n        [4, 1, 4, 4, 3],\n        [1, 0, 3, 2, 4]]),\n array([[4, 4, 3, 3, 2],\n        [0, 1, 0, 2, 1],\n        [3, 0, 1, 1, 0],\n        [1, 2, 4, 0, 3],\n        [2, 3, 2, 4, 4]]),\n array([[3, 2, 4, 1, 1],\n        [2, 0, 1, 0, 0],\n        [4, 3, 0, 4, 2],\n        [0, 4, 2, 3, 3],\n        [1, 1, 3, 2, 4]]),\n array([[4, 3, 1, 4, 0],\n        [0, 2, 4, 1, 2],\n        [2, 0, 3, 0, 1],\n        [3, 1, 2, 2, 3],\n        [1, 4, 0, 3, 4]]),\n array([[3, 2, 0, 3, 0],\n        [2, 4, 3, 0, 4],\n        [4, 1, 1, 1, 1],\n        [1, 0, 2, 4, 2],\n        [0, 3, 4, 2, 3]]),\n array([[1, 1, 4, 4, 0],\n        [2, 2, 3, 3, 1],\n        [3, 0, 0, 0, 3],\n        [0, 3, 1, 2, 4],\n        [4, 4, 2, 1, 2]]),\n array([[2, 0, 1, 3, 3],\n        [0, 2, 4, 4, 1],\n        [1, 4, 3, 1, 0],\n        [4, 3, 0, 2, 2],\n        [3, 1, 2, 0, 4]])]"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\n# Convert each (5x5) prediction array to a rank order\nfinal_predicted_rankings = []\n\nfor prediction_matrix in predicted_rankings:\n    # Sum across rows to get a single score for each image\n    image_scores = prediction_matrix.sum(axis=1)\n    # Get the ranking order based on scores (higher score means higher rank)\n    ranked_order = np.argsort(image_scores)[::-1] + 1\n    final_predicted_rankings.append(ranked_order.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T17:57:55.136429Z","iopub.execute_input":"2024-11-12T17:57:55.137710Z","iopub.status.idle":"2024-11-12T17:57:55.144812Z","shell.execute_reply.started":"2024-11-12T17:57:55.137652Z","shell.execute_reply":"2024-11-12T17:57:55.143840Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"final_predicted_rankings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T17:58:04.089540Z","iopub.execute_input":"2024-11-12T17:58:04.090021Z","iopub.status.idle":"2024-11-12T17:58:04.099973Z","shell.execute_reply.started":"2024-11-12T17:58:04.089978Z","shell.execute_reply":"2024-11-12T17:58:04.098605Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[[4, 2, 3, 5, 1],\n [5, 1, 3, 4, 2],\n [4, 2, 3, 1, 5],\n [1, 5, 3, 2, 4],\n [5, 1, 2, 4, 3],\n [5, 1, 2, 3, 4],\n [4, 3, 2, 5, 1],\n [4, 5, 2, 1, 3],\n [1, 5, 4, 3, 2],\n [3, 4, 5, 1, 2],\n [5, 1, 4, 2, 3],\n [2, 5, 4, 3, 1],\n [5, 2, 4, 1, 3],\n [4, 2, 5, 3, 1]]"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Get the indices of the test data points\ntest_indices = test_dataset.indices\n\n# Display the indices\nprint(\"Test Indices:\", test_indices)\n\n# Optionally, print the actual test data points (e.g., true rankings or other features)\ntrue_test_rankings = [eval(target_data.iloc[idx]['target']) for idx in test_indices]\ntrue_test_rankings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T17:58:48.610884Z","iopub.execute_input":"2024-11-12T17:58:48.611358Z","iopub.status.idle":"2024-11-12T17:58:48.624289Z","shell.execute_reply.started":"2024-11-12T17:58:48.611315Z","shell.execute_reply":"2024-11-12T17:58:48.622912Z"}},"outputs":[{"name":"stdout","text":"Test Indices: [40, 30, 8, 53, 21, 37, 18, 68, 61, 46, 11, 15, 12, 25]\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[[1, 4, 5, 3, 2],\n [4, 1, 2, 5, 3],\n [2, 3, 4, 5, 1],\n [2, 4, 1, 5, 3],\n [1, 5, 2, 4, 3],\n [4, 2, 3, 1, 5],\n [2, 4, 3, 5, 1],\n [2, 5, 3, 1, 4],\n [3, 5, 1, 4, 2],\n [1, 2, 5, 4, 3],\n [3, 1, 2, 5, 4],\n [1, 2, 3, 4, 5],\n [5, 3, 4, 1, 2],\n [2, 3, 4, 5, 1]]"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def mean_reciprocal_rank(true_rankings, predicted_rankings):\n    reciprocal_ranks = []\n    for true, pred in zip(true_rankings, predicted_rankings):\n        for i, p in enumerate(pred):\n            if p == true[i]:\n                reciprocal_ranks.append(1 / (i + 1))\n                break\n        else:\n            reciprocal_ranks.append(0)\n    return np.mean(reciprocal_ranks)\nprint(mean_reciprocal_rank(true_test_rankings,final_predicted_rankings))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T18:02:25.217643Z","iopub.execute_input":"2024-11-12T18:02:25.218231Z","iopub.status.idle":"2024-11-12T18:02:25.229120Z","shell.execute_reply.started":"2024-11-12T18:02:25.218180Z","shell.execute_reply":"2024-11-12T18:02:25.227516Z"}},"outputs":[{"name":"stdout","text":"0.294047619047619\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from scipy.stats import kendalltau\n\ndef kendall_tau_score(true_rankings, predicted_rankings):\n    scores = [kendalltau(true, pred).correlation for true, pred in zip(true_rankings, predicted_rankings)]\n    return np.mean([s for s in scores if s is not None])\nprint(kendall_tau_score(true_test_rankings,final_predicted_rankings))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T18:04:27.855504Z","iopub.execute_input":"2024-11-12T18:04:27.856007Z","iopub.status.idle":"2024-11-12T18:04:27.872113Z","shell.execute_reply.started":"2024-11-12T18:04:27.855962Z","shell.execute_reply":"2024-11-12T18:04:27.870665Z"}},"outputs":[{"name":"stdout","text":"0.1571428571428571\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from scipy.stats import spearmanr\n\n# Spearman correlation function\ndef spearman_correlation(true_rankings, predicted_rankings):\n    correlations = []\n    for true, pred in zip(true_rankings, predicted_rankings):\n        correlation, _ = spearmanr(true, pred)\n        correlations.append(correlation if not pd.isnull(correlation) else 0)  # Handle NaN cases\n    average_correlation = sum(correlations) / len(correlations)\n    return average_correlation\nprint(spearman_correlation(true_test_rankings,final_predicted_rankings))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T18:06:32.244647Z","iopub.execute_input":"2024-11-12T18:06:32.245685Z","iopub.status.idle":"2024-11-12T18:06:32.289777Z","shell.execute_reply.started":"2024-11-12T18:06:32.245626Z","shell.execute_reply":"2024-11-12T18:06:32.288511Z"}},"outputs":[{"name":"stdout","text":"0.20714285714285713\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}