{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9887405,"sourceType":"datasetVersion","datasetId":6071977},{"sourceId":9887408,"sourceType":"datasetVersion","datasetId":6071980},{"sourceId":9887719,"sourceType":"datasetVersion","datasetId":6072181}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Libraries and Define Dependencies\r\nThis section imports necessary libraries for data processing, model creation, and training. We use libraries like `pandas` for data manipulation, `torch` for model training, and `transformers` for BERT integration.\r\n","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom transformers import BertModel, BertTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T18:42:11.216014Z","iopub.execute_input":"2024-11-12T18:42:11.217203Z","iopub.status.idle":"2024-11-12T18:42:19.012475Z","shell.execute_reply.started":"2024-11-12T18:42:11.217141Z","shell.execute_reply":"2024-11-12T18:42:19.011481Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Load Data\r\nHere, we load the training data and target data for our multimodal ranking task.\r\n","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/semval-dataset/train/subtask_a_train.csv')\ntarget_data = pd.read_csv('/kaggle/input/target-column-dataset/target_t.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:28:32.909246Z","iopub.execute_input":"2024-11-12T19:28:32.909949Z","iopub.status.idle":"2024-11-12T19:28:32.934942Z","shell.execute_reply.started":"2024-11-12T19:28:32.909891Z","shell.execute_reply":"2024-11-12T19:28:32.933896Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Define Image Transformations\r\nWe define a series of image transformations to preprocess images before feeding them into the ResNet model. These include resizing, normalization, and tensor conversion.\r\n","metadata":{}},{"cell_type":"code","source":"image_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T18:43:17.695002Z","iopub.execute_input":"2024-11-12T18:43:17.695873Z","iopub.status.idle":"2024-11-12T18:43:17.701777Z","shell.execute_reply.started":"2024-11-12T18:43:17.695815Z","shell.execute_reply":"2024-11-12T18:43:17.700387Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Define the Dataset Class\r\nThis custom dataset class handles the loading of images and text data. It also tokenizes text inputs with BERT's tokenizer and retrieves image features for each idiom.\r\n","metadata":{}},{"cell_type":"code","source":"class IdiomImageDataset(Dataset):\n    def __init__(self, dataframe, target_df, image_dir):\n        self.dataframe = dataframe\n        self.target_df = target_df\n        self.image_dir = image_dir\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        row = self.dataframe.iloc[index]\n        target_row = self.target_df.iloc[index]\n        sentence = row['sentence']\n        idiom_name = row['compound'].replace(\"'\", \"_\")\n        image_names = [row[f'image{i}_name'] for i in range(1, 6)]\n\n        expected_order = eval(target_row['target'])\n        expected_order = [x - 1 for x in expected_order]\n\n        inputs = self.tokenizer(sentence, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n        images = []\n        for img_name in image_names:\n            img_path = os.path.join(self.image_dir, idiom_name, img_name)\n            img = Image.open(img_path).convert('RGB')\n            img = image_transforms(img)\n            images.append(img)\n        images_tensor = torch.stack(images)\n        expected_order_tensor = torch.tensor(expected_order, dtype=torch.long)\n        return inputs['input_ids'].squeeze(0), inputs['attention_mask'].squeeze(0), images_tensor, expected_order_tensor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T18:43:39.046209Z","iopub.execute_input":"2024-11-12T18:43:39.046664Z","iopub.status.idle":"2024-11-12T18:43:39.057696Z","shell.execute_reply.started":"2024-11-12T18:43:39.046622Z","shell.execute_reply":"2024-11-12T18:43:39.056493Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Define the Model Class\r\nWe define a multimodal ranking model that combines text features from BERT and image features from ResNet. These features are merged, passed through fully connected layers, and used to predict the ranking of images.\r\n","metadata":{}},{"cell_type":"code","source":"class MultimodalRankingModel(nn.Module):\n    def __init__(self):\n        super(MultimodalRankingModel, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.resnet = models.resnet50(weights='DEFAULT')\n        self.resnet.fc = nn.Identity()\n        self.fc1 = nn.Linear(768 + 2048, 512)\n        self.dropout = nn.Dropout(0.3)\n        self.fc2 = nn.Linear(512, 5)\n\n    def forward(self, input_ids, attention_mask, images):\n        text_features = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n        text_features = text_features.mean(dim=1)\n        \n        batch_size, num_images, channels, height, width = images.size()\n        images = images.view(batch_size * num_images, channels, height, width)\n        image_features = self.resnet(images)\n        image_features = image_features.view(batch_size, num_images, -1)\n        \n        combined_features = torch.cat((text_features.unsqueeze(1).expand(-1, num_images, -1), image_features), dim=2)\n        x = torch.relu(self.fc1(combined_features))\n        x = self.dropout(x)\n        rankings = self.fc2(x).squeeze(-1)  # Shape: [batch_size, num_images]\n        \n        return rankings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T18:44:12.950389Z","iopub.execute_input":"2024-11-12T18:44:12.950878Z","iopub.status.idle":"2024-11-12T18:44:12.961137Z","shell.execute_reply.started":"2024-11-12T18:44:12.950833Z","shell.execute_reply":"2024-11-12T18:44:12.959826Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Prepare Data and Split into Train and Test Sets\r\nWe initialize the dataset and split it into training and testing sets. The data loaders help with batch loading of data during training.\r\n","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Set a seed for reproducibility\ntorch.manual_seed(42)\n\n# Define image folder and initialize dataset\nimage_folder = '/kaggle/input/semval-dataset/train'\ndataset = IdiomImageDataset(train_data, target_data, image_folder)\n\n# Define static train-test split\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\n# Initialize data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:28:38.099761Z","iopub.execute_input":"2024-11-12T19:28:38.100935Z","iopub.status.idle":"2024-11-12T19:28:38.431316Z","shell.execute_reply.started":"2024-11-12T19:28:38.100871Z","shell.execute_reply":"2024-11-12T19:28:38.429913Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# Initialize Model, Optimizer, and Loss Function\r\nWe initialize our multimodal ranking model, set up an optimizer (Adam), and specify cross-entropy loss as the loss function for ranking.\r\n","metadata":{}},{"cell_type":"code","source":"model = MultimodalRankingModel()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\ncriterion = nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T18:45:23.967848Z","iopub.execute_input":"2024-11-12T18:45:23.969105Z","iopub.status.idle":"2024-11-12T18:45:28.012761Z","shell.execute_reply.started":"2024-11-12T18:45:23.969049Z","shell.execute_reply":"2024-11-12T18:45:28.011570Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf2d3d9f8c9c40b1a42dd41e629faac9"}},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 148MB/s] \n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Training Function\r\nThis function performs model training over a specified number of epochs, iterating through the data loader and updating model weights based on the calculated loss.\r\n","metadata":{}},{"cell_type":"code","source":"def train_model(model, data_loader, criterion, optimizer, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for input_ids, attention_mask, images, expected_order in data_loader:\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask, images)\n            loss = 0\n            for i in range(outputs.size(1)):  # Loop over each image's rank\n                loss += criterion(outputs[:, i], expected_order[:, i])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        \n        print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data_loader)}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T18:45:51.763681Z","iopub.execute_input":"2024-11-12T18:45:51.764095Z","iopub.status.idle":"2024-11-12T18:45:51.772004Z","shell.execute_reply.started":"2024-11-12T18:45:51.764059Z","shell.execute_reply":"2024-11-12T18:45:51.770692Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Run Training\r\nWe now run the training process and save the trained model weights.\r\n","metadata":{}},{"cell_type":"code","source":"train_model(model, train_loader, criterion, optimizer, epochs=10)\ntorch.save(model.state_dict(), 'multimodal_ranking_model.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:28:43.137868Z","iopub.execute_input":"2024-11-12T19:28:43.139150Z","iopub.status.idle":"2024-11-12T19:51:21.827880Z","shell.execute_reply.started":"2024-11-12T19:28:43.139092Z","shell.execute_reply":"2024-11-12T19:51:21.826221Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 4.664624571800232\nEpoch 2/10, Loss: 3.915795624256134\nEpoch 3/10, Loss: 3.0234537720680237\nEpoch 4/10, Loss: 2.3471586108207703\nEpoch 5/10, Loss: 1.7941093742847443\nEpoch 6/10, Loss: 1.205925703048706\nEpoch 7/10, Loss: 0.859320729970932\nEpoch 8/10, Loss: 0.5839527547359467\nEpoch 9/10, Loss: 0.41342754662036896\nEpoch 10/10, Loss: 0.32215698063373566\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Model Evaluation\r\nThe evaluation function uses the test dataset to generate rankings and compares predicted rankings against the true rankings.\r\n","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, data_loader):\n    model.eval()\n    all_predictions = []\n    with torch.no_grad():\n        for input_ids, attention_mask, images, _ in data_loader:\n            outputs = model(input_ids, attention_mask, images)\n            rankings = torch.argsort(outputs, dim=1)\n            all_predictions.extend(rankings.cpu().numpy())\n    return all_predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:51:39.165015Z","iopub.execute_input":"2024-11-12T19:51:39.165460Z","iopub.status.idle":"2024-11-12T19:51:39.173030Z","shell.execute_reply.started":"2024-11-12T19:51:39.165412Z","shell.execute_reply":"2024-11-12T19:51:39.171647Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Calculate Ranking Accuracy\r\nHere, we convert the predicted ranking matrix into ordered arrays and calculate metrics such as Mean Reciprocal Rank (MRR) and Kendall Tau score for ranking accuracy evaluation.\r\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\npredicted_rankings = evaluate_model(model, test_loader)\n\n# Convert each (5x5) prediction array to a rank order\nfinal_predicted_rankings = []\nfor prediction_matrix in predicted_rankings:\n    image_scores = prediction_matrix.sum(axis=1)\n    ranked_order = np.argsort(image_scores)[::-1] + 1\n    final_predicted_rankings.append(ranked_order.tolist())\n\n# Get the test indices\ntest_indices = test_dataset.indices\nprint(\"Test Indices:\", test_indices)\n\n# True rankings for comparison\ntrue_test_rankings = [eval(target_data.iloc[idx]['target']) for idx in test_indices]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:51:54.057152Z","iopub.execute_input":"2024-11-12T19:51:54.058145Z","iopub.status.idle":"2024-11-12T19:52:04.840872Z","shell.execute_reply.started":"2024-11-12T19:51:54.058027Z","shell.execute_reply":"2024-11-12T19:52:04.839746Z"}},"outputs":[{"name":"stdout","text":"Test Indices: [46, 1, 35, 4, 40, 11, 8, 44, 34, 52, 21, 48, 53, 67]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"final_predicted_rankings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:52:13.216191Z","iopub.execute_input":"2024-11-12T19:52:13.216664Z","iopub.status.idle":"2024-11-12T19:52:13.226788Z","shell.execute_reply.started":"2024-11-12T19:52:13.216620Z","shell.execute_reply":"2024-11-12T19:52:13.225500Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[[1, 4, 5, 3, 2],\n [2, 3, 4, 1, 5],\n [4, 1, 5, 3, 2],\n [2, 3, 5, 4, 1],\n [4, 3, 2, 5, 1],\n [4, 5, 3, 1, 2],\n [3, 4, 5, 2, 1],\n [4, 5, 2, 1, 3],\n [4, 2, 3, 5, 1],\n [5, 3, 4, 2, 1],\n [1, 4, 5, 2, 3],\n [1, 5, 4, 2, 3],\n [1, 4, 5, 3, 2],\n [3, 5, 4, 1, 2]]"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"true_test_rankings ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:52:24.511012Z","iopub.execute_input":"2024-11-12T19:52:24.511443Z","iopub.status.idle":"2024-11-12T19:52:24.520717Z","shell.execute_reply.started":"2024-11-12T19:52:24.511403Z","shell.execute_reply":"2024-11-12T19:52:24.519347Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[[1, 2, 5, 4, 3],\n [2, 4, 3, 1, 5],\n [3, 1, 5, 2, 4],\n [4, 3, 1, 2, 5],\n [1, 4, 5, 3, 2],\n [3, 1, 2, 5, 4],\n [2, 3, 4, 5, 1],\n [2, 4, 1, 3, 5],\n [3, 4, 1, 5, 2],\n [1, 3, 2, 4, 5],\n [1, 5, 2, 4, 3],\n [1, 3, 5, 2, 4],\n [2, 4, 1, 5, 3],\n [3, 2, 5, 1, 4]]"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"def mean_reciprocal_rank(true_rankings, predicted_rankings):\n    reciprocal_ranks = []\n    for true, pred in zip(true_rankings, predicted_rankings):\n        for i, p in enumerate(pred):\n            if p == true[i]:\n                reciprocal_ranks.append(1 / (i + 1))\n                break\n        else:\n            reciprocal_ranks.append(0)\n    return np.mean(reciprocal_ranks)\nprint(mean_reciprocal_rank(true_test_rankings,final_predicted_rankings))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:53:09.518239Z","iopub.execute_input":"2024-11-12T19:53:09.518705Z","iopub.status.idle":"2024-11-12T19:53:09.528313Z","shell.execute_reply.started":"2024-11-12T19:53:09.518660Z","shell.execute_reply":"2024-11-12T19:53:09.526772Z"}},"outputs":[{"name":"stdout","text":"0.5321428571428571\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import numpy as np\n\ndef calculate_ranking_accuracy(predicted_rankings, true_rankings):\n    \"\"\"\n    Calculate the percentage of images ranked correctly.\n    \n    Parameters:\n    predicted_rankings (list of list of int): The predicted ranking for each image set.\n    true_rankings (list of list of int): The true ranking for each image set.\n    \n    Returns:\n    float: The average percentage of images ranked correctly.\n    \"\"\"\n    assert len(predicted_rankings) == len(true_rankings), \"Predicted and true rankings must have the same length.\"\n    \n    total_correct = 0\n    total_images = 0\n    \n    for pred_ranking, true_ranking in zip(predicted_rankings, true_rankings):\n        # Count correctly ranked images\n        correct = sum(1 for p, t in zip(pred_ranking, true_ranking) if p == t)\n        total_correct += correct\n        total_images += len(true_ranking)\n    \n    accuracy = (total_correct / total_images) * 100\n    return accuracy\n\naccuracy = calculate_ranking_accuracy(true_test_rankings,final_predicted_rankings)\nprint(f\"Ranking Accuracy: {accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T19:58:57.028038Z","iopub.execute_input":"2024-11-12T19:58:57.028764Z","iopub.status.idle":"2024-11-12T19:58:57.042350Z","shell.execute_reply.started":"2024-11-12T19:58:57.028705Z","shell.execute_reply":"2024-11-12T19:58:57.039649Z"}},"outputs":[{"name":"stdout","text":"Ranking Accuracy: 25.71%\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}